import numpy as np
import pandas as pd

from sklearn.model_selection import train_test_split

from keras.models import Sequential
from keras.layers import Dense


df1=pd.read_csv('Boston.csv')
# For input, select all rows and all columns except first and last
X = df1.iloc[:,1:-1]
# For output, select last column
y=df1['medv']

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=123)
mean = X_train.mean(axis=0)
std = X_train.std(axis=0)
X_train = (X_train - mean) / std
X_test = (X_test - mean) / std

# Build ANN for regression
model = Sequential()
# First layer has 128 units, input shape is 13x1 because there are 13 input features, activation is relu
model.add(Dense(128, input_shape=(13, ), activation='relu'))
# Second layer has 64 units, activation is relu
model.add(Dense(64, activation='relu'))
# Output layer has 1 unit (because we are predicting one value), activation is linear
model.add(Dense(1, activation='linear'))


# Compile model - Loss function is MSE
model.compile(optimizer='adam', loss='mse', metrics=['mae'])
model.summary()
history = model.fit(X_train, y_train, epochs=25, validation_split=0.05)

# Evaluating test data
mse_nn, mae_nn = model.evaluate(X_test, y_test)
print('Mean squared error on test data: ', mse_nn)
print('Mean absolute error on test data: ', mae_nn)

# Comparison with traditional approaches

from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error
from sklearn.metrics import mean_absolute_error
lr_model = LinearRegression()
lr_model.fit(X_train, y_train)

y_pred_lr = lr_model.predict(X_test)
mse_lr = mean_squared_error(y_test, y_pred_lr)
mae_lr = mean_absolute_error(y_test, y_pred_lr)
print('Mean squared error on test data: ', mse_lr)
print('Mean absolute error on test data: ', mae_lr)

